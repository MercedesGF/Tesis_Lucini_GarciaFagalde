{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717a1957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "     Year  Country  BN.CAB.XOKA.GD.ZS  BX.KLT.DINV.WD.GD.ZS  DBT-EXP  Default  \\\n",
      "0    1970        1                NaN                   NaN      3.0        0   \n",
      "1    1971        1                NaN                   NaN      6.0        0   \n",
      "2    1972        1                NaN                   0.0      2.0        0   \n",
      "3    1973        1                NaN                   0.0      3.0        0   \n",
      "4    1974        1                NaN                   0.0      6.0        0   \n",
      "..    ...      ...                ...                   ...      ...      ...   \n",
      "290  2024        5                NaN                   NaN      NaN        0   \n",
      "291  2025        5                NaN                   NaN      NaN        0   \n",
      "292  2026        5                NaN                   NaN      NaN        0   \n",
      "293  2027        5                NaN                   NaN      NaN        0   \n",
      "294  2028        5                NaN                   NaN      NaN        0   \n",
      "\n",
      "     DT.DIS.DECB.CD  DT.DIS.DEGG.CD  DT.DIS.DEPS.CD  DT.DIS.DLTF.CD  ...  \\\n",
      "0          285000.0     223056732.0     461187631.0    9.265664e+08  ...   \n",
      "1          993000.0     270951107.0     527090923.0    1.098318e+09  ...   \n",
      "2       143156099.0     195116950.0     555224158.0    1.360072e+09  ...   \n",
      "3       212719964.0     192288066.0     850199510.0    1.279458e+09  ...   \n",
      "4         1147000.0     414783658.0     996268447.0    1.488251e+09  ...   \n",
      "..              ...             ...             ...             ...  ...   \n",
      "290             NaN             NaN             NaN             NaN  ...   \n",
      "291             NaN             NaN             NaN             NaN  ...   \n",
      "292             NaN             NaN             NaN             NaN  ...   \n",
      "293             NaN             NaN             NaN             NaN  ...   \n",
      "294             NaN             NaN             NaN             NaN  ...   \n",
      "\n",
      "     NY.GDP.DEFL.KD.ZG  NY.GDP.DEFL.KD.ZG.AD  NY.GDP.MKTP.KD.ZG  \\\n",
      "0                  NaN                   NaN                NaN   \n",
      "1                 20.0                   NaN                NaN   \n",
      "2                 29.0                   NaN                2.0   \n",
      "3                 26.0                   NaN                3.0   \n",
      "4                 29.0                   NaN                6.0   \n",
      "..                 ...                   ...                ...   \n",
      "290                NaN                   3.0                3.0   \n",
      "291                NaN                   2.0                2.0   \n",
      "292                NaN                   4.0                4.0   \n",
      "293                NaN                   2.0                2.0   \n",
      "294                NaN                   2.0                2.0   \n",
      "\n",
      "     NY.GDP.MKTP.PP.CD  NY.GDP.PCAP.CD  PA.NUS.FCRF  PX.REX.REER  \\\n",
      "0                  NaN          1323.0          0.0          NaN   \n",
      "1                  NaN          1372.0          0.0          NaN   \n",
      "2                  NaN          1409.0          0.0          NaN   \n",
      "3                  NaN          2097.0          0.0          NaN   \n",
      "4                  NaN          2845.0          0.0          NaN   \n",
      "..                 ...             ...          ...          ...   \n",
      "290                NaN             NaN          NaN          NaN   \n",
      "291                NaN             NaN          NaN          NaN   \n",
      "292                NaN             NaN          NaN          NaN   \n",
      "293                NaN             NaN          NaN          NaN   \n",
      "294                NaN             NaN          NaN          NaN   \n",
      "\n",
      "     SH.XPD.CHEX.GD.ZS  SL.UEM.TOTL.NE.ZS  Unnamed: 69  \n",
      "0                  NaN                NaN          NaN  \n",
      "1                  NaN                NaN          NaN  \n",
      "2                  NaN                7.0          NaN  \n",
      "3                  NaN                6.0          NaN  \n",
      "4                  NaN                3.0          NaN  \n",
      "..                 ...                ...          ...  \n",
      "290                NaN                NaN          NaN  \n",
      "291                NaN                NaN          NaN  \n",
      "292                NaN                NaN          NaN  \n",
      "293                NaN                NaN          NaN  \n",
      "294                NaN                NaN          NaN  \n",
      "\n",
      "[295 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{ sys . executable } -m pip install pandas\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "pd . read_excel(\"/Users/ma.mercedesgarciafagalde/Desktop/Base de Datos - Junio 11.xlsx\")\n",
    "df = pd . read_excel(\"/Users/ma.mercedesgarciafagalde/Desktop/Base de Datos - Junio 11.xlsx\")\n",
    "print(df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea91c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Country  BN.CAB.XOKA.GD.ZS  BX.KLT.DINV.WD.GD.ZS   DBT-EXP  \\\n",
      "0    1970        1          -0.813333              1.514286  3.000000   \n",
      "1    1971        1          -0.813333              1.514286  6.000000   \n",
      "2    1972        1          -0.813333              0.000000  2.000000   \n",
      "3    1973        1          -0.813333              0.000000  3.000000   \n",
      "4    1974        1          -0.813333              0.000000  6.000000   \n",
      "..    ...      ...                ...                   ...       ...   \n",
      "290  2024        5          -0.813333              1.514286  3.360784   \n",
      "291  2025        5          -0.813333              1.514286  3.360784   \n",
      "292  2026        5          -0.813333              1.514286  3.360784   \n",
      "293  2027        5          -0.813333              1.514286  3.360784   \n",
      "294  2028        5          -0.813333              1.514286  3.360784   \n",
      "\n",
      "     Default  DT.DIS.DECB.CD  DT.DIS.DEGG.CD  DT.DIS.DEPS.CD  DT.DIS.DLTF.CD  \\\n",
      "0          0    2.850000e+05    2.230567e+08    4.611876e+08    9.265664e+08   \n",
      "1          0    9.930000e+05    2.709511e+08    5.270909e+08    1.098318e+09   \n",
      "2          0    1.431561e+08    1.951170e+08    5.552242e+08    1.360072e+09   \n",
      "3          0    2.127200e+08    1.922881e+08    8.501995e+08    1.279458e+09   \n",
      "4          0    1.147000e+06    4.147837e+08    9.962684e+08    1.488251e+09   \n",
      "..       ...             ...             ...             ...             ...   \n",
      "290        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "291        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "292        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "293        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "294        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "\n",
      "     ...  NY.GDP.DEFL.KD.ZG  NY.GDP.DEFL.KD.ZG.AD  NY.GDP.MKTP.KD.ZG  \\\n",
      "0    ...          57.622047             75.022989           7.575758   \n",
      "1    ...          20.000000             75.022989           7.575758   \n",
      "2    ...          29.000000             75.022989           2.000000   \n",
      "3    ...          26.000000             75.022989           3.000000   \n",
      "4    ...          29.000000             75.022989           6.000000   \n",
      "..   ...                ...                   ...                ...   \n",
      "290  ...          57.622047              3.000000           3.000000   \n",
      "291  ...          57.622047              2.000000           2.000000   \n",
      "292  ...          57.622047              4.000000           4.000000   \n",
      "293  ...          57.622047              2.000000           2.000000   \n",
      "294  ...          57.622047              2.000000           2.000000   \n",
      "\n",
      "     NY.GDP.MKTP.PP.CD  NY.GDP.PCAP.CD  PA.NUS.FCRF  PX.REX.REER  \\\n",
      "0         8.168785e+10    1.323000e+03     0.000000   853.534314   \n",
      "1         8.168785e+10    1.372000e+03     0.000000   853.534314   \n",
      "2         8.168785e+10    1.409000e+03     0.000000   853.534314   \n",
      "3         8.168785e+10    2.097000e+03     0.000000   853.534314   \n",
      "4         8.168785e+10    2.845000e+03     0.000000   853.534314   \n",
      "..                 ...             ...          ...          ...   \n",
      "290       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "291       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "292       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "293       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "294       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "\n",
      "     SH.XPD.CHEX.GD.ZS  SL.UEM.TOTL.NE.ZS  Unnamed: 69  \n",
      "0           117.164384           6.440945     5.705882  \n",
      "1           117.164384           6.440945     5.705882  \n",
      "2           117.164384           7.000000     5.705882  \n",
      "3           117.164384           6.000000     5.705882  \n",
      "4           117.164384           3.000000     5.705882  \n",
      "..                 ...                ...          ...  \n",
      "290         117.164384           6.440945     5.705882  \n",
      "291         117.164384           6.440945     5.705882  \n",
      "292         117.164384           6.440945     5.705882  \n",
      "293         117.164384           6.440945     5.705882  \n",
      "294         117.164384           6.440945     5.705882  \n",
      "\n",
      "[295 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "## Reemplazamos los valores de variables con missing values por la media de cada columna\n",
    "df = df.fillna(df.mean())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a825262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evalua_metodo(modelo, X_train, Y_train, X_test, Y_test):\n",
    "    '''\n",
    "    Esta función calcula la matriz de confusion, el accuracy y el AUC, ademas de graficar la curva roc y calcular el ECM. \n",
    "    Al final la función nos devuelve un data frame con los resultados de estas métricas para el modelo seleccionado en \n",
    "    base a los datos ingresados.\n",
    "    Input: \n",
    "        modelo: un modelo con los parámetros ya definidos.\n",
    "        X_train, Y_train, X_test, Y_test: Datos de entrenamiento y test ya divididos.\n",
    "    Output:\n",
    "        Matriz especificando VP, FP, VN, FN, Accuracy, AUC, ECM.\n",
    "        Además imprime la matriz de confusión, el Accuracy, el AUC y grafica la curva de ROC.\n",
    "    '''\n",
    "    # Ajustamos el modelo\n",
    "    modelo.fit(X_train, Y_train)\n",
    "    \n",
    "    # Realizamos predicción sobre base test\n",
    "    global Y_pred \n",
    "    Y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calculamos el accuracy y matriz de confusion\n",
    "    matriz_confusion = confusion_matrix(Y_test, Y_pred)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    auc = roc_auc_score(Y_test, Y_pred)\n",
    "    \n",
    "\n",
    "    # Graficamos la curva de roc\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, Y_pred)\n",
    "    \n",
    "    #Calculamos ECM\n",
    "    ecm = mean_squared_error(Y_pred, Y_test)\n",
    "    \n",
    "    #Guardamos los resultados en un dataframe creado con más columnas que nos servirán para las otras funciones\n",
    "    output = pd.DataFrame(columns = [\"Modelo\", \"Penalty\", \"Hiperparámetro\", \"VP\", \"FP\", \"VN\", \"FN\", \"Accuracy\", \"AUC\", \"ECM\"])\n",
    "    output = output.append({\"VP\" : matriz_confusion[0][0], \"FP\": matriz_confusion[0][1], \"VN\": matriz_confusion[1][1], \"FN\": matriz_confusion[1][0], \"Accuracy\" : accuracy, \"AUC\" : auc, \"ECM\" : ecm}, ignore_index = True)\n",
    "\n",
    "    return output, fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce08292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LISTA EN VEZ DE DICCIONARIO\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib.pyplot import boxplot\n",
    "\n",
    "def cross_validation(X, y, nombre, modelo, penalty = \"l1\", hyper_list = [1, 5, 10], p = 5):\n",
    "    '''\n",
    "    Esta función realiza p-fold cross validation para distintos modelos, lista de hiperparámetros y data set determinado. Para eso, itera sobre una lista de hiperparámetros, crea p distintas particiones de la data y guarda los resultados en un dataframe.\n",
    "    Input: \n",
    "        X: Matriz de predictores.\n",
    "        y: Variable dependiente.\n",
    "        modelo: Modelo a utilizar.\n",
    "        penalty: Tipo de regularización (\"l1\": Lasso, \"l2\": Ridge, \"elasticnet\": Elastic Net).\n",
    "        hyper_list: Lista de hiperparámetros a evaluar.\n",
    "        p: Cantidad de particiones a realizar.\n",
    "    Output:\n",
    "        Dataframe por modelo e hierparámetro con el ECM promedio de las distintas particiones.\n",
    "    '''\n",
    "    \n",
    "    #Creamos la matriz en la que vamos a guardar los outputs\n",
    "    datos = pd.DataFrame(columns=[\"Modelo\", \"Particion\", \"Penalty\", \"Lambda\", \"ECM\"])\n",
    "    \n",
    "    #Reseteamos el indice de las matrices a utilizar para que funcione bien el split\n",
    "    X.reset_index(inplace = True, drop = True)\n",
    "    y.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    \n",
    "    #Iteramos sobre los lambdas\n",
    "    for hiper in hyper_list:\n",
    "        \n",
    "        kf = KFold(n_splits=p, shuffle=True, random_state = 1265465)\n",
    "        #Iteramos sobre las distintas particiones\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(X)): \n",
    "            \n",
    "            #Separamos los datos en train y test\n",
    "            x_train, x_test = X.reindex(train_index), X.reindex(test_index)\n",
    "            y_train, y_test = y.reindex(train_index), y.reindex(test_index)\n",
    "            \n",
    "            #Usamos evalua_metodo para obtener el ecm y agregamos los datos al dataframe\n",
    "            if nombre == \"Regresión logística\":\n",
    "                evalua_metodo(modelo(penalty = penalty, C = 1/hiper, solver='saga', l1_ratio = 0.5,random_state=1, max_iter = 1000) , x_train , y_train, x_test, y_test)\n",
    "            if nombre == \"KNN\":\n",
    "                evalua_metodo(modelo(n_neighbors = hiper) , x_train , y_train, x_test, y_test)\n",
    "            if nombre == \"Arbol de decisión\" or nombre  == \"Boosting\":\n",
    "                evalua_metodo(modelo(max_depth = hiper, random_state = 1) , x_train , y_train, x_test, y_test)\n",
    "            if nombre == \"Support Vector Machines (SVM)\":\n",
    "                evalua_metodo(modelo(C = 1/hiper, random_state = 1, max_iter = -1) , x_train , y_train, x_test, y_test)\n",
    "            if nombre  == \"Bagging\":\n",
    "                evalua_metodo(modelo(n_estimators = hiper, random_state = 1) , x_train , y_train, x_test, y_test)\n",
    "            if nombre == \"Boosting\" or nombre  == \"Random Forests\":\n",
    "                evalua_metodo(modelo(n_estimators = hiper, random_state = 1) , x_train , y_train, x_test, y_test)\n",
    "            \n",
    "            ecm = mean_squared_error(Y_pred, y_test)\n",
    "            datos = datos.append({\"Modelo\" : nombre, \"Particion\" : i, \"Penalty\" : penalty if (nombre == \"Regresión logística\") else \"-\", \"Hiperparámetro\": hiper ,\"ECM\" : ecm}, ignore_index = True)\n",
    "    \n",
    "    #Reseteamos el indice para arreglar un problema de formato     \n",
    "    datos.reset_index(inplace = True)\n",
    "    \n",
    "    #Agrupamos el dataframe en base a modelo, penalty y lambda para calcular el ECM promedio entre las particiones\n",
    "    datos = datos.groupby([\"Modelo\", 'Penalty', \"Hiperparámetro\"]).agg({'ECM':'mean'})\n",
    "\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b43328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_config(nombre, modelo, hyper_list, X, y, penalty = [\"l1\"], p = 5):\n",
    "    '''\n",
    "    Esta función utiliza la función cross_validation y elije el hiperparámetro óptimo (el que minimza ECM promedio en las distintas particiones) para cada modelo.\n",
    "    Input:\n",
    "        modelo: Modelo a utilizar.\n",
    "        hyper_list: Lista de hiperparámetros a evaluar.\n",
    "        X: Matriz de predictores.\n",
    "        y: Variable dependiente.\n",
    "        penalty: Lista con los tipos de regularización (\"l1\": Lasso, \"l2\": Ridge, \"elasticnet\": Elastic Net) a probar.\n",
    "        p: Cantidad de particiones a realizar en cross validation.\n",
    "    Output:\n",
    "        Dataframe con un hiperparámetro óptimo y el ECM correspondiente para cada modelo.\n",
    "    '''\n",
    "    \n",
    "    #Creamos el dataframe donde guardamos el output\n",
    "    lambdas_opt = pd.DataFrame(columns=[\"Modelo\", \"Penalty\", \"Hiperparámetro\", \"ECM\"])\n",
    "    \n",
    "    #Iteramos sobre los distintos penalties\n",
    "    if nombre == \"Regresión logística\":\n",
    "        for pen in penalty:\n",
    "            #Usamos cross_validation para obtener los resultados en base al penalty\n",
    "            datos2 = cross_validation(X, y, nombre, modelo, pen, hyper_list, p)\n",
    "    else:\n",
    "        datos2 = cross_validation(X, y, nombre, modelo, \"-\", hyper_list, p)\n",
    "    datos2.reset_index(inplace = True)\n",
    "    #Lo agregamos a la matriz de output\n",
    "    lambdas_opt = lambdas_opt.append(datos2.loc[datos2[\"ECM\"].idxmin()], ignore_index = True)\n",
    "       \n",
    "    return lambdas_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f44a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def evalua_multiples_metodos(X, y, penalty = [\"l1\", \"l2\", \"elasticnet\"], logreg_lambda = [0.00001, 0.001, 0.1, 1, 10], k_neigh = [1, 5, 10], max_depth = [1, 3, 5], C = [0.001, 0.1, 10], n_estimators = [1, 20, 50], p = 5):\n",
    "    '''\n",
    "    Esta función itera sobre varios modelos (Regresión logística, Análisis discriminante lineal, KNN, Arbol de decisión, Support Vector Machines (SVM), Bagging, Random Forests, Boosting) para obtener varias métricas de performance (VP, FP, VN, FN, Accuracy, AUC, ECM) bajo distintos esquemas, y las guarda en un dataframe. Además, realiza primero validación cruzada para obtener el hiperparámetro óptimo.\n",
    "    Input:\n",
    "        X: Matriz de predictores.\n",
    "        y: Variable dependiente.\n",
    "        penalty: Lista con los tipos de regularización (\"l1\": Lasso, \"l2\": Ridge, \"elasticnet\": Elastic Net) a probar en cross validation\n",
    "        logreg_lambda: Lista de hiperparámetros a evaluar en regresión logística.\n",
    "        p: Cantidad de particiones a realizar en cross validation.\n",
    "        k_neigh: Lista de valores de k a evaluar en k vecinos cercanos.\n",
    "        max_depth: Lista de valores a evaluar en árboles de decisión y Boosting.\n",
    "        C: Lista de valores a evaluar en SVM.\n",
    "        n_estimators: Lista de valores a evaluar en Random Forest y Bagging.\n",
    "    Output:\n",
    "        Matriz por cada modelo con el hiperparámetro óptimo, y las métricas de performance.\n",
    "    '''\n",
    "    \n",
    "    #Dividimos la muestra en test y train para usar en los casos que no utilizan cross_validation\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "    \n",
    "    #Creamos un diccionario para iterar sobre los modelos\n",
    "    modelos_lista = {\"Regresión logística\" : LogisticRegression, \"Análisis discriminante lineal\" : LinearDiscriminantAnalysis, \"KNN\" : KNeighborsClassifier, \"Arbol de decisión\" : DecisionTreeClassifier, \"Support Vector Machines (SVM)\" : SVC, \"Bagging\" : BaggingClassifier, \"Random Forests\" : RandomForestClassifier, \"Boosting\" : GradientBoostingClassifier}\n",
    "    \n",
    "    #Creamos el dataframe de output\n",
    "    output = pd.DataFrame(columns = [\"Modelo\", \"Penalty\", \"Hiperparámetro\", \"VP\", \"FP\", \"VN\", \"FN\", \"Accuracy\", \"AUC\", \"ECM\"])\n",
    "    \n",
    "    #Iteramos sobre los modelos\n",
    "    for nombre, modelo in modelos_lista.items():\n",
    "        #Si es una regresión logística, obtenemos el lambda óptimo con evalua_config y luego usamos ese lambda para obtener los resultados con evalua_metodo\n",
    "        if nombre != \"Análisis discriminante lineal\":\n",
    "            \n",
    "            if nombre == \"Regresión logística\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, logreg_lambda, X, y, penalty, p)\n",
    "                output = output.append(evalua_metodo(modelo(penalty = lambdas_opt[\"Penalty\"][0], C = 1/lambdas_opt[\"Hiperparámetro\"][0], l1_ratio = 0.5, solver = \"saga\"), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            if nombre == \"KNN\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, k_neigh, X, y, p = p)\n",
    "                output = output.append(evalua_metodo(modelo(np.int_(lambdas_opt[\"Hiperparámetro\"][0])), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            if nombre == \"Arbol de decisión\" or nombre  == \"Boosting\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, max_depth, X, y, p = p)\n",
    "                output = output.append(evalua_metodo(modelo(max_depth = 3, random_state = 1), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            if nombre == \"Support Vector Machines (SVM)\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, C, X, y, p = p)\n",
    "                output = output.append(evalua_metodo(modelo(C = 3, random_state = 1), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            if nombre  == \"Random Forests\" or nombre == \"Bagging\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, n_estimators, X, y, p = p)\n",
    "                output = output.append(evalua_metodo(modelo(n_estimators = np.int_(lambdas_opt[\"Hiperparámetro\"][0]), random_state = 1), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "\n",
    "                \n",
    "            output.loc[len(output)-1, [\"Modelo\", \"Penalty\", \"Hiperparámetro\"]] = lambdas_opt.at[0, \"Modelo\"], lambdas_opt.at[0, \"Penalty\"], lambdas_opt.at[0, \"Hiperparámetro\"]\n",
    "            \n",
    "        #Para el resto de los casos, simplemente usamos evalua_metodo para obtener los resultados\n",
    "        else:\n",
    "            output = output.append(evalua_metodo(modelo(), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            output.loc[len(output)-1, \"Modelo\"] = nombre\n",
    "            output.fillna(\"-\", inplace = True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5498449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "259919b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos nuestras dos variables, la dependiente (y) y la independiente (x)\n",
    "default = df['Default']\n",
    "X = df.drop(\"Default\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e81dc790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275\n",
       "1     20\n",
       "Name: Default, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3cd10fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Default                 1.000000\n",
       "DT.DIS.DECB.CD          0.126058\n",
       "DT.DOD.DEPS.CD          0.124830\n",
       "DT.DOD.DPPG.CD          0.124823\n",
       "DT.DOD.PUBS.CD          0.124741\n",
       "                          ...   \n",
       "PA.NUS.FCRF            -0.099311\n",
       "FI.RES.TOTL.DT.ZS.1    -0.121378\n",
       "FI.RES.TOTL.DT.ZS      -0.128018\n",
       "BX.KLT.DINV.WD.GD.ZS   -0.137376\n",
       "DBT-EXP                -0.155620\n",
       "Name: Default, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowcorrelated_features = set()\n",
    "correlation_matrix = df.corr()\n",
    "correlation_matrix[\"Default\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "290382dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(correlation_matrix .columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) >0.0<0.05:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            lowcorrelated_features.add(colname)\n",
    "len(lowcorrelated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "395134a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PA.NUS.FCRF', 'DT.DOD.DECT.CD', 'GC.DOD.TOTL.GD.ZS', 'DT.DIS.PRPG.CD', 'FP.CPI.TOTL.ZG', 'NE.CON.GOVT.ZS', 'DT.DOD.ALLC.CD', 'NE.EXP.GNFS.ZS', 'DT.DIS.DLXF.CD', 'NE.IMP.GNFS.ZS', 'DT.GPA.DPPG', 'DT.TDS.DECT.CD', 'NY.GDP.PCAP.CD', 'Country', 'DT.DIS.DEGG.CD', 'DT.INR.DPPG', 'GC.REV.GOTR.ZS', 'DT.TDS.PRPG.CD', 'BN.CAB.XOKA.GD.ZS', 'DT.NFL.DEGG.CD', 'GC.TAX.TOTL.GD.ZS', 'NY.GDP.MKTP.KD.ZG', 'DT.NFL.DSTC.CD', 'BX.KLT.DINV.WD.GD.ZS', 'DT.DOD.DLXF.CD', 'DT.INT.DECT.CD', 'DT.MAT.DPPG', 'DT.NFL.DPNG.CD', 'FI.RES.TOTL.DT.ZS', 'DT.DOD.DEGG.CD', 'FI.RES.TOTL.DT.ZS.1', 'Unnamed: 69', 'DT.DIS.DEPS.CD', 'DT.GRE.DPPG', 'DT.DIS.DOPS.CD', 'NE.DAB.TOTL.ZS', 'NY.GDP.MKTP.PP.CD', 'GC.REV.XGRT.GD.ZS', 'NY.GDP.DEFL.KD.ZG.AD', 'SH.XPD.CHEX.GD.ZS', 'DT.NFL.DECT.CD', 'DT.TDS.DEPS.CD', 'DT.DOD.DPPG.CD', 'DT.NFL.DEPS.CD', 'DT.DOD.PUBS.CD', 'FI.RES.TOTL.CD', 'DT.DIS.DECB.CD', 'DT.TDS.DOPS.CD', 'DT.TDS.DECB.CD', 'NY.GDP.DEFL.KD.ZG', 'DT.DOD.PRVS.CD', 'FM.LBL.BMNY.IR.ZS', 'DT.DOD.DEPS.CD', 'DT.NFL.DLXF.CD', 'DT.NFL.DPPG.CD', 'DT.NFL.PRPG.CD', 'DBT-EXP', 'DT.DIS.DPPG.CD', 'DT.NFL.DOPS.CD', 'PX.REX.REER', 'Default', 'DT.DOD.DSTC.ZS', 'DT.DIS.DLTF.CD', 'DT.TDS.DPNG.CD', 'SL.UEM.TOTL.NE.ZS', 'DT.DIS.DPNG.CD', 'DT.TDS.DPPG.CD', 'DT.DOD.DOPS.CD', 'DT.TDS.DLXF.CD'}\n"
     ]
    }
   ],
   "source": [
    "print(lowcorrelated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c5e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=lowcorrelated_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f20aadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Penalty</th>\n",
       "      <th>Hiperparámetro</th>\n",
       "      <th>VP</th>\n",
       "      <th>FP</th>\n",
       "      <th>VN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>ECM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regresión logística</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.089888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Análisis discriminante lineal</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.168539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>-</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.089888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arbol de decisión</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.157303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machines (SVM)</td>\n",
       "      <td>-</td>\n",
       "      <td>10.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.089888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>-</td>\n",
       "      <td>50.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.123596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>-</td>\n",
       "      <td>20.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.089888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boosting</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.168539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Modelo Penalty Hiperparámetro    VP   FP   VN   FN  \\\n",
       "0            Regresión logística      l2        0.00001  81.0  0.0  0.0  8.0   \n",
       "1  Análisis discriminante lineal       -              -  74.0  7.0  0.0  8.0   \n",
       "2                            KNN       -            5.0  81.0  0.0  0.0  8.0   \n",
       "3              Arbol de decisión       -            1.0  75.0  6.0  0.0  8.0   \n",
       "4  Support Vector Machines (SVM)       -           10.0  81.0  0.0  0.0  8.0   \n",
       "5                        Bagging       -           50.0  78.0  3.0  0.0  8.0   \n",
       "6                 Random Forests       -           20.0  81.0  0.0  0.0  8.0   \n",
       "7                       Boosting       -            1.0  74.0  7.0  0.0  8.0   \n",
       "\n",
       "   Accuracy       AUC       ECM  \n",
       "0  0.910112  0.500000  0.089888  \n",
       "1  0.831461  0.456790  0.168539  \n",
       "2  0.910112  0.500000  0.089888  \n",
       "3  0.842697  0.462963  0.157303  \n",
       "4  0.910112  0.500000  0.089888  \n",
       "5  0.876404  0.481481  0.123596  \n",
       "6  0.910112  0.500000  0.089888  \n",
       "7  0.831461  0.456790  0.168539  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalua_multiples_metodos(X, default, [\"l1\", \"l2\"], p = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "022d2032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Default'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Default'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f9a1be5e26c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Para ver desigualdad entre 1 y 0 en variable default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcount_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcount_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Frequency by observation number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Default'"
     ]
    }
   ],
   "source": [
    "## Para ver desigualdad entre 1 y 0 en variable default\n",
    "count_classes = pd.value_counts(df['Default'], sort = True)\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Default\")\n",
    "plt.ylabel(\"Number of Observations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pearson correlation entre variables\n",
    "import pandas as pd \n",
    "from scipy.stats import pearsonr \n",
    "  \n",
    "list1 = df['DT.DOD.DSTC.ZS'] \n",
    "list2 = df['Default'] \n",
    "  \n",
    "corr, _ = pearsonr(list1, list2) \n",
    "print('Pearsons correlation: %.3f' % corr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e60e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matriz de correlacion entre variables \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "correlation_df=df[['Default', 'GC.DOD.TOTL.GD.ZS','NY.GDP.MKTP.KD.ZG', 'DT.DOD.DSTC.ZS']]\n",
    "corr = correlation_df.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True)\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715ae12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
