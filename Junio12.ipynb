{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717a1957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "     Year  Country  BN.CAB.XOKA.GD.ZS  BX.KLT.DINV.WD.GD.ZS  DBT-EXP  Default  \\\n",
      "0    1970        1                NaN                   NaN      3.0        0   \n",
      "1    1971        1                NaN                   NaN      6.0        0   \n",
      "2    1972        1                NaN                   0.0      2.0        0   \n",
      "3    1973        1                NaN                   0.0      3.0        0   \n",
      "4    1974        1                NaN                   0.0      6.0        0   \n",
      "..    ...      ...                ...                   ...      ...      ...   \n",
      "290  2024        5                NaN                   NaN      NaN        0   \n",
      "291  2025        5                NaN                   NaN      NaN        0   \n",
      "292  2026        5                NaN                   NaN      NaN        0   \n",
      "293  2027        5                NaN                   NaN      NaN        0   \n",
      "294  2028        5                NaN                   NaN      NaN        0   \n",
      "\n",
      "     DT.DIS.DECB.CD  DT.DIS.DEGG.CD  DT.DIS.DEPS.CD  DT.DIS.DLTF.CD  ...  \\\n",
      "0          285000.0     223056732.0     461187631.0    9.265664e+08  ...   \n",
      "1          993000.0     270951107.0     527090923.0    1.098318e+09  ...   \n",
      "2       143156099.0     195116950.0     555224158.0    1.360072e+09  ...   \n",
      "3       212719964.0     192288066.0     850199510.0    1.279458e+09  ...   \n",
      "4         1147000.0     414783658.0     996268447.0    1.488251e+09  ...   \n",
      "..              ...             ...             ...             ...  ...   \n",
      "290             NaN             NaN             NaN             NaN  ...   \n",
      "291             NaN             NaN             NaN             NaN  ...   \n",
      "292             NaN             NaN             NaN             NaN  ...   \n",
      "293             NaN             NaN             NaN             NaN  ...   \n",
      "294             NaN             NaN             NaN             NaN  ...   \n",
      "\n",
      "     NY.GDP.DEFL.KD.ZG  NY.GDP.DEFL.KD.ZG.AD  NY.GDP.MKTP.KD.ZG  \\\n",
      "0                  NaN                   NaN                NaN   \n",
      "1                 20.0                   NaN                NaN   \n",
      "2                 29.0                   NaN                2.0   \n",
      "3                 26.0                   NaN                3.0   \n",
      "4                 29.0                   NaN                6.0   \n",
      "..                 ...                   ...                ...   \n",
      "290                NaN                   3.0                3.0   \n",
      "291                NaN                   2.0                2.0   \n",
      "292                NaN                   4.0                4.0   \n",
      "293                NaN                   2.0                2.0   \n",
      "294                NaN                   2.0                2.0   \n",
      "\n",
      "     NY.GDP.MKTP.PP.CD  NY.GDP.PCAP.CD  PA.NUS.FCRF  PX.REX.REER  \\\n",
      "0                  NaN          1323.0          0.0          NaN   \n",
      "1                  NaN          1372.0          0.0          NaN   \n",
      "2                  NaN          1409.0          0.0          NaN   \n",
      "3                  NaN          2097.0          0.0          NaN   \n",
      "4                  NaN          2845.0          0.0          NaN   \n",
      "..                 ...             ...          ...          ...   \n",
      "290                NaN             NaN          NaN          NaN   \n",
      "291                NaN             NaN          NaN          NaN   \n",
      "292                NaN             NaN          NaN          NaN   \n",
      "293                NaN             NaN          NaN          NaN   \n",
      "294                NaN             NaN          NaN          NaN   \n",
      "\n",
      "     SH.XPD.CHEX.GD.ZS  SL.UEM.TOTL.NE.ZS  Unnamed: 69  \n",
      "0                  NaN                NaN          NaN  \n",
      "1                  NaN                NaN          NaN  \n",
      "2                  NaN                7.0          NaN  \n",
      "3                  NaN                6.0          NaN  \n",
      "4                  NaN                3.0          NaN  \n",
      "..                 ...                ...          ...  \n",
      "290                NaN                NaN          NaN  \n",
      "291                NaN                NaN          NaN  \n",
      "292                NaN                NaN          NaN  \n",
      "293                NaN                NaN          NaN  \n",
      "294                NaN                NaN          NaN  \n",
      "\n",
      "[295 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{ sys . executable } -m pip install pandas\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "pd . read_excel(\"/Users/ma.mercedesgarciafagalde/Desktop/Base de Datos - Junio 11.xlsx\")\n",
    "df = pd . read_excel(\"/Users/ma.mercedesgarciafagalde/Desktop/Base de Datos - Junio 11.xlsx\")\n",
    "print(df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea91c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Country  BN.CAB.XOKA.GD.ZS  BX.KLT.DINV.WD.GD.ZS   DBT-EXP  \\\n",
      "0    1970        1          -0.813333              1.514286  3.000000   \n",
      "1    1971        1          -0.813333              1.514286  6.000000   \n",
      "2    1972        1          -0.813333              0.000000  2.000000   \n",
      "3    1973        1          -0.813333              0.000000  3.000000   \n",
      "4    1974        1          -0.813333              0.000000  6.000000   \n",
      "..    ...      ...                ...                   ...       ...   \n",
      "290  2024        5          -0.813333              1.514286  3.360784   \n",
      "291  2025        5          -0.813333              1.514286  3.360784   \n",
      "292  2026        5          -0.813333              1.514286  3.360784   \n",
      "293  2027        5          -0.813333              1.514286  3.360784   \n",
      "294  2028        5          -0.813333              1.514286  3.360784   \n",
      "\n",
      "     Default  DT.DIS.DECB.CD  DT.DIS.DEGG.CD  DT.DIS.DEPS.CD  DT.DIS.DLTF.CD  \\\n",
      "0          0    2.850000e+05    2.230567e+08    4.611876e+08    9.265664e+08   \n",
      "1          0    9.930000e+05    2.709511e+08    5.270909e+08    1.098318e+09   \n",
      "2          0    1.431561e+08    1.951170e+08    5.552242e+08    1.360072e+09   \n",
      "3          0    2.127200e+08    1.922881e+08    8.501995e+08    1.279458e+09   \n",
      "4          0    1.147000e+06    4.147837e+08    9.962684e+08    1.488251e+09   \n",
      "..       ...             ...             ...             ...             ...   \n",
      "290        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "291        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "292        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "293        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "294        0    1.017204e+08    1.907649e+09    2.112526e+09    3.771118e+09   \n",
      "\n",
      "     ...  NY.GDP.DEFL.KD.ZG  NY.GDP.DEFL.KD.ZG.AD  NY.GDP.MKTP.KD.ZG  \\\n",
      "0    ...          57.622047             75.022989           7.575758   \n",
      "1    ...          20.000000             75.022989           7.575758   \n",
      "2    ...          29.000000             75.022989           2.000000   \n",
      "3    ...          26.000000             75.022989           3.000000   \n",
      "4    ...          29.000000             75.022989           6.000000   \n",
      "..   ...                ...                   ...                ...   \n",
      "290  ...          57.622047              3.000000           3.000000   \n",
      "291  ...          57.622047              2.000000           2.000000   \n",
      "292  ...          57.622047              4.000000           4.000000   \n",
      "293  ...          57.622047              2.000000           2.000000   \n",
      "294  ...          57.622047              2.000000           2.000000   \n",
      "\n",
      "     NY.GDP.MKTP.PP.CD  NY.GDP.PCAP.CD  PA.NUS.FCRF  PX.REX.REER  \\\n",
      "0         8.168785e+10    1.323000e+03     0.000000   853.534314   \n",
      "1         8.168785e+10    1.372000e+03     0.000000   853.534314   \n",
      "2         8.168785e+10    1.409000e+03     0.000000   853.534314   \n",
      "3         8.168785e+10    2.097000e+03     0.000000   853.534314   \n",
      "4         8.168785e+10    2.845000e+03     0.000000   853.534314   \n",
      "..                 ...             ...          ...          ...   \n",
      "290       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "291       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "292       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "293       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "294       8.168785e+10    1.371519e+11  1503.098039   853.534314   \n",
      "\n",
      "     SH.XPD.CHEX.GD.ZS  SL.UEM.TOTL.NE.ZS  Unnamed: 69  \n",
      "0           117.164384           6.440945     5.705882  \n",
      "1           117.164384           6.440945     5.705882  \n",
      "2           117.164384           7.000000     5.705882  \n",
      "3           117.164384           6.000000     5.705882  \n",
      "4           117.164384           3.000000     5.705882  \n",
      "..                 ...                ...          ...  \n",
      "290         117.164384           6.440945     5.705882  \n",
      "291         117.164384           6.440945     5.705882  \n",
      "292         117.164384           6.440945     5.705882  \n",
      "293         117.164384           6.440945     5.705882  \n",
      "294         117.164384           6.440945     5.705882  \n",
      "\n",
      "[295 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "## Reemplazamos los valores de variables con missing values por la media de cada columna\n",
    "df = df.fillna(df.mean())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a825262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evalua_metodo(modelo, X_train, Y_train, X_test, Y_test):\n",
    "    '''\n",
    "    Esta función calcula la matriz de confusion, el accuracy y el AUC, ademas de graficar la curva roc y calcular el ECM. \n",
    "    Al final la función nos devuelve un data frame con los resultados de estas métricas para el modelo seleccionado en \n",
    "    base a los datos ingresados.\n",
    "    Input: \n",
    "        modelo: un modelo con los parámetros ya definidos.\n",
    "        X_train, Y_train, X_test, Y_test: Datos de entrenamiento y test ya divididos.\n",
    "    Output:\n",
    "        Matriz especificando VP, FP, VN, FN, Accuracy, AUC, ECM.\n",
    "        Además imprime la matriz de confusión, el Accuracy, el AUC y grafica la curva de ROC.\n",
    "    '''\n",
    "    # Ajustamos el modelo\n",
    "    modelo.fit(X_train, Y_train)\n",
    "    \n",
    "    # Realizamos predicción sobre base test\n",
    "    global Y_pred \n",
    "    Y_pred = modelo.predict(X_test)\n",
    "\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    X, y = load_breast_cancer(return_X_y=True)\n",
    "    clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n",
    "    roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
    "    \n",
    "    # Calculamos el accuracy y matriz de confusion\n",
    "    matriz_confusion = confusion_matrix(Y_test, Y_pred)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    auc = roc_auc_score(Y_test, Y_pred)\n",
    "    \n",
    "\n",
    "    # Graficamos la curva de roc\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, Y_pred)\n",
    "    \n",
    "    #Calculamos ECM\n",
    "    ecm = mean_squared_error(Y_pred, Y_test)\n",
    "    \n",
    "    #Guardamos los resultados en un dataframe creado con más columnas que nos servirán para las otras funciones\n",
    "    output = pd.DataFrame(columns = [\"Modelo\", \"Penalty\", \"Hiperparámetro\", \"VP\", \"FP\", \"VN\", \"FN\", \"Accuracy\", \"AUC\", \"ECM\"])\n",
    "    output = output.append({\"VP\" : matriz_confusion[0][0], \"FP\": matriz_confusion[0][1], \"VN\": matriz_confusion[1][1], \"FN\": matriz_confusion[1][0], \"Accuracy\" : accuracy, \"AUC\" : auc, \"ECM\" : ecm}, ignore_index = True)\n",
    "\n",
    "    return output, fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce08292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LISTA EN VEZ DE DICCIONARIO\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib.pyplot import boxplot\n",
    "\n",
    "def cross_validation(X, y, nombre, modelo, penalty = \"l1\", hyper_list = [1, 5, 10], p = 5):\n",
    "    '''\n",
    "    Esta función realiza p-fold cross validation para distintos modelos, lista de hiperparámetros y data set determinado. Para eso, itera sobre una lista de hiperparámetros, crea p distintas particiones de la data y guarda los resultados en un dataframe.\n",
    "    Input: \n",
    "        X: Matriz de predictores.\n",
    "        y: Variable dependiente.\n",
    "        modelo: Modelo a utilizar.\n",
    "        penalty: Tipo de regularización (\"l1\": Lasso, \"l2\": Ridge, \"elasticnet\": Elastic Net).\n",
    "        hyper_list: Lista de hiperparámetros a evaluar.\n",
    "        p: Cantidad de particiones a realizar.\n",
    "    Output:\n",
    "        Dataframe por modelo e hierparámetro con el ECM promedio de las distintas particiones.\n",
    "    '''\n",
    "    \n",
    "    #Creamos la matriz en la que vamos a guardar los outputs\n",
    "    datos = pd.DataFrame(columns=[\"Modelo\", \"Particion\", \"Penalty\", \"Lambda\", \"ECM\"])\n",
    "    \n",
    "    #Reseteamos el indice de las matrices a utilizar para que funcione bien el split\n",
    "    X.reset_index(inplace = True, drop = True)\n",
    "    y.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    \n",
    "    #Iteramos sobre los lambdas\n",
    "    for hiper in hyper_list:\n",
    "        \n",
    "        kf = KFold(n_splits=p, shuffle=True, random_state = 1265465)\n",
    "        #Iteramos sobre las distintas particiones\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(X)): \n",
    "            \n",
    "            #Separamos los datos en train y test\n",
    "            x_train, x_test = X.reindex(train_index), X.reindex(test_index)\n",
    "            y_train, y_test = y.reindex(train_index), y.reindex(test_index)\n",
    "            \n",
    "            #Usamos evalua_metodo para obtener el ecm y agregamos los datos al dataframe\n",
    "            if nombre == \"Regresión logística\":\n",
    "                evalua_metodo(modelo(penalty = penalty, C = 1/hiper, solver='saga', l1_ratio = 0.5,random_state=1, max_iter = 1000) , x_train , y_train, x_test, y_test)\n",
    "            if nombre == \"KNN\":\n",
    "                evalua_metodo(modelo(n_neighbors = hiper) , x_train , y_train, x_test, y_test)\n",
    "            if nombre == \"Arbol de decisión\" or nombre  == \"Boosting\":\n",
    "                evalua_metodo(modelo(max_depth = hiper, random_state = 1) , x_train , y_train, x_test, y_test)\n",
    "            if nombre == \"Support Vector Machines (SVM)\":\n",
    "                evalua_metodo(modelo(C = 1/hiper, random_state = 1, max_iter = -1) , x_train , y_train, x_test, y_test)\n",
    "            if nombre  == \"Bagging\":\n",
    "                evalua_metodo(modelo(n_estimators = hiper, random_state = 1) , x_train , y_train, x_test, y_test)\n",
    "            if nombre == \"Boosting\" or nombre  == \"Random Forests\":\n",
    "                evalua_metodo(modelo(n_estimators = hiper, random_state = 1) , x_train , y_train, x_test, y_test)\n",
    "            \n",
    "            ecm = mean_squared_error(Y_pred, y_test)\n",
    "            datos = datos.append({\"Modelo\" : nombre, \"Particion\" : i, \"Penalty\" : penalty if (nombre == \"Regresión logística\") else \"-\", \"Hiperparámetro\": hiper ,\"ECM\" : ecm}, ignore_index = True)\n",
    "    \n",
    "    #Reseteamos el indice para arreglar un problema de formato     \n",
    "    datos.reset_index(inplace = True)\n",
    "    \n",
    "    #Generamos el boxplot para cada penalty\n",
    "    box_datos = pd.DataFrame(np.column_stack(np.split(datos[\"ECM\"], len(hyper_list))), columns = hyper_list)\n",
    "    box_datos = boxplot(box_datos, labels = hyper_list)\n",
    "    plt.show()\n",
    "    \n",
    "    #Agrupamos el dataframe en base a modelo, penalty y lambda para calcular el ECM promedio entre las particiones\n",
    "    datos = datos.groupby([\"Modelo\", 'Penalty', \"Hiperparámetro\"]).agg({'ECM':'mean'})\n",
    "\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b43328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_config(nombre, modelo, hyper_list, X, y, penalty = [\"l1\"], p = 5):\n",
    "    '''\n",
    "    Esta función utiliza la función cross_validation y elije el hiperparámetro óptimo (el que minimza ECM promedio en las distintas particiones) para cada modelo.\n",
    "    Input:\n",
    "        modelo: Modelo a utilizar.\n",
    "        hyper_list: Lista de hiperparámetros a evaluar.\n",
    "        X: Matriz de predictores.\n",
    "        y: Variable dependiente.\n",
    "        penalty: Lista con los tipos de regularización (\"l1\": Lasso, \"l2\": Ridge, \"elasticnet\": Elastic Net) a probar.\n",
    "        p: Cantidad de particiones a realizar en cross validation.\n",
    "    Output:\n",
    "        Dataframe con un hiperparámetro óptimo y el ECM correspondiente para cada modelo.\n",
    "    '''\n",
    "    \n",
    "    #Creamos el dataframe donde guardamos el output\n",
    "    lambdas_opt = pd.DataFrame(columns=[\"Modelo\", \"Penalty\", \"Hiperparámetro\", \"ECM\"])\n",
    "    \n",
    "    #Iteramos sobre los distintos penalties\n",
    "    if nombre == \"Regresión logística\":\n",
    "        for pen in penalty:\n",
    "            #Usamos cross_validation para obtener los resultados en base al penalty\n",
    "            datos2 = cross_validation(X, y, nombre, modelo, pen, hyper_list, p)\n",
    "    else:\n",
    "        datos2 = cross_validation(X, y, nombre, modelo, \"-\", hyper_list, p)\n",
    "    datos2.reset_index(inplace = True)\n",
    "    #Lo agregamos a la matriz de output\n",
    "    lambdas_opt = lambdas_opt.append(datos2.loc[datos2[\"ECM\"].idxmin()], ignore_index = True)\n",
    "       \n",
    "    return lambdas_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f44a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def evalua_multiples_metodos(X, y, penalty = [\"l1\", \"l2\", \"elasticnet\"], logreg_lambda = [0.00001, 0.001, 0.1, 1, 10], k_neigh = [1, 5, 10], max_depth = [5, 10, 15], C = [0.001, 0.1, 10], n_estimators = [1, 20, 50], p = 5):\n",
    "    '''\n",
    "    Esta función itera sobre varios modelos (Regresión logística, Análisis discriminante lineal, KNN, Arbol de decisión, Support Vector Machines (SVM), Bagging, Random Forests, Boosting) para obtener varias métricas de performance (VP, FP, VN, FN, Accuracy, AUC, ECM) bajo distintos esquemas, y las guarda en un dataframe. Además, realiza primero validación cruzada para obtener el hiperparámetro óptimo.\n",
    "    Input:\n",
    "        X: Matriz de predictores.\n",
    "        y: Variable dependiente.\n",
    "        penalty: Lista con los tipos de regularización (\"l1\": Lasso, \"l2\": Ridge, \"elasticnet\": Elastic Net) a probar en cross validation\n",
    "        logreg_lambda: Lista de hiperparámetros a evaluar en regresión logística.\n",
    "        p: Cantidad de particiones a realizar en cross validation.\n",
    "        k_neigh: Lista de valores de k a evaluar en k vecinos cercanos.\n",
    "        max_depth: Lista de valores a evaluar en árboles de decisión y Boosting.\n",
    "        C: Lista de valores a evaluar en SVM.\n",
    "        n_estimators: Lista de valores a evaluar en Random Forest y Bagging.\n",
    "    Output:\n",
    "        Matriz por cada modelo con el hiperparámetro óptimo, y las métricas de performance.\n",
    "    '''\n",
    "    \n",
    "    #Dividimos la muestra en test y train para usar en los casos que no utilizan cross_validation\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "    \n",
    "    #Creamos un diccionario para iterar sobre los modelos\n",
    "    modelos_lista = {\"Regresión logística\" : LogisticRegression, \"Análisis discriminante lineal\" : LinearDiscriminantAnalysis, \"KNN\" : KNeighborsClassifier, \"Arbol de decisión\" : DecisionTreeClassifier, \"Support Vector Machines (SVM)\" : SVC, \"Bagging\" : BaggingClassifier, \"Random Forests\" : RandomForestClassifier, \"Boosting\" : GradientBoostingClassifier}\n",
    "    \n",
    "    #Creamos el dataframe de output\n",
    "    output = pd.DataFrame(columns = [\"Modelo\", \"Penalty\", \"Hiperparámetro\", \"VP\", \"FP\", \"VN\", \"FN\", \"Accuracy\", \"AUC\", \"ECM\"])\n",
    "    \n",
    "    #Iteramos sobre los modelos\n",
    "    for nombre, modelo in modelos_lista.items():\n",
    "        #Si es una regresión logística, obtenemos el lambda óptimo con evalua_config y luego usamos ese lambda para obtener los resultados con evalua_metodo\n",
    "        if nombre != \"Análisis discriminante lineal\":\n",
    "            \n",
    "            if nombre == \"Regresión logística\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, logreg_lambda, X, y, penalty, p)\n",
    "                output = output.append(evalua_metodo(modelo(penalty = lambdas_opt[\"Penalty\"][0], C = 1/lambdas_opt[\"Hiperparámetro\"][0], l1_ratio = 0.5, solver = \"saga\"), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            if nombre == \"KNN\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, k_neigh, X, y, p = p)\n",
    "                output = output.append(evalua_metodo(modelo(np.int_(lambdas_opt[\"Hiperparámetro\"][0])), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            if nombre == \"Arbol de decisión\" or nombre  == \"Boosting\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, max_depth, X, y, p = p)\n",
    "                output = output.append(evalua_metodo(modelo(max_depth = lambdas_opt[\"Hiperparámetro\"][0], random_state = 1), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            if nombre == \"Support Vector Machines (SVM)\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, C, X, y, p = p)\n",
    "                output = output.append(evalua_metodo(modelo(1/lambdas_opt[\"Hiperparámetro\"][0], random_state = 1), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            if nombre  == \"Random Forests\" or nombre == \"Bagging\":\n",
    "                lambdas_opt = evalua_config(nombre, modelo, n_estimators, X, y, p = p)\n",
    "                output = output.append(evalua_metodo(modelo(n_estimators = np.int_(lambdas_opt[\"Hiperparámetro\"][0]), random_state = 1), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "\n",
    "                \n",
    "            output.loc[len(output)-1, [\"Modelo\", \"Penalty\", \"Hiperparámetro\"]] = lambdas_opt.at[0, \"Modelo\"], lambdas_opt.at[0, \"Penalty\"], lambdas_opt.at[0, \"Hiperparámetro\"]\n",
    "            \n",
    "        #Para el resto de los casos, simplemente usamos evalua_metodo para obtener los resultados\n",
    "        else:\n",
    "            output = output.append(evalua_metodo(modelo(), X_train, Y_train, X_test, Y_test)[0], ignore_index = True)\n",
    "            output.loc[len(output)-1, \"Modelo\"] = nombre\n",
    "            output.fillna(\"-\", inplace = True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5498449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "259919b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos nuestras dos variables, la dependiente (y) y la independiente (x)\n",
    "default = df['Default']\n",
    "X = df.drop(\"Default\", axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e81dc790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275\n",
       "1     20\n",
       "Name: Default, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83063d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/ma.mercedesgarciafagalde/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f8833c122f41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevalua_multiples_metodos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-118ec77136a7>\u001b[0m in \u001b[0;36mevalua_multiples_metodos\u001b[0;34m(X, y, penalty, logreg_lambda, k_neigh, max_depth, C, n_estimators, p)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnombre\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Regresión logística\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mlambdas_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalua_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnombre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogreg_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalua_metodo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambdas_opt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Penalty\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlambdas_opt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Hiperparámetro\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnombre\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"KNN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-68806d01a3fa>\u001b[0m in \u001b[0;36mevalua_config\u001b[0;34m(nombre, modelo, hyper_list, X, y, penalty, p)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m#Usamos cross_validation para obtener los resultados en base al penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mdatos2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnombre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdatos2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnombre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9d806ca67f85>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(X, y, nombre, modelo, penalty, hyper_list, p)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m#Usamos evalua_metodo para obtener el ecm y agregamos los datos al dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnombre\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Regresión logística\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mevalua_metodo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mhiper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saga'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnombre\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"KNN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mevalua_metodo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhiper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-402b5cb7bbc2>\u001b[0m in \u001b[0;36mevalua_metodo\u001b[0;34m(modelo, X_train, Y_train, X_test, Y_test)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmatriz_confusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         return _average_binary_score(\n\u001b[0m\u001b[1;32m    570\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;34m\"\"\"Binary roc auc score.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"Only one class present in y_true. ROC AUC score \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;34m\"is not defined in that case.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "evalua_multiples_metodos(X, default, [\"l1\", \"l2\"], p = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para ver desigualdad entre 1 y 0 en variable default\n",
    "count_classes = pd.value_counts(df['Default'], sort = True)\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Default\")\n",
    "plt.ylabel(\"Number of Observations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pearson correlation entre variables\n",
    "import pandas as pd \n",
    "from scipy.stats import pearsonr \n",
    "  \n",
    "list1 = df['DT.DOD.DSTC.ZS'] \n",
    "list2 = df['Default'] \n",
    "  \n",
    "corr, _ = pearsonr(list1, list2) \n",
    "print('Pearsons correlation: %.3f' % corr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e60e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matriz de correlacion entre variables \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "correlation_df=df[['Default', 'GC.DOD.TOTL.GD.ZS','NY.GDP.MKTP.KD.ZG', 'DT.DOD.DSTC.ZS']]\n",
    "corr = correlation_df.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True)\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28244850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
